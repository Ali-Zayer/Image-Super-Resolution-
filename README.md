# Image-Super-Resolution-
SRResNet-SRGAN
In recent years, there have been several advancements in the picture super-resolution problem employing the most current architectures based on deep learning. These advancements have allowed for improved accuracy and faster processing times. In recent years, there has been a rise in interest in the scientific topic of super resolution, which pertains to image processing. It has recently come to the attention of researchers in the field of image processing that Single Picture Super Resolution (SISR), which creates a High-resolution (HR) image from a single Low-resolution (LR) image, is an interest-ing study topic. 
The construction of SR algorithms via the use of a deep learning model, such as Super-Resolution Generative Adversarial Networks (SRGANs), is growing bigger and more complicated, necessitating an enormous amount of memory capacity. To overcome these difficulties, however, it is challenging to run deep learning models on mobile devices since such models often include millions of parameters. Recent research has shown that generative adversarial networks, often known as GANs, are capable of producing pictures that are perceptually convincing (SR) by the effective ex-traction of high-frequency information from a single low-resolution (LR) image.
The purpose of this study is to find a solution to this problem by improving the performance of Generative Adversarial Networks (GANs) for super-resolution pictures by the use of an evolution-based method for the cascade network modulation. In order to train the model, we make use of something called an SRGAN, where the generative adversarial network is made up of a discrimina-tive network and a generating network. The discrimination network is used to judge the reliability of the generated image, which is a framework that is capable of inferring realistic natural images of (4 upscaling) factors. The generator network is used to generate high-resolution images, and the discrim-ination network is used to judge the reliability of the generated image. The behavior of optimization-based ultra-fine techniques is largely determined by the objective function that is selected to be opti-mized for. (Kaggle Notebook), which is a cloud computing platform that enables collaborative and reproducible analysis, is what we are utilizing, and the (DIV2K) dataset is what we consider to be the gold standard. PyTorch was the framework that was used to build our model, along with a Graphics Processing Unit (GPU).
